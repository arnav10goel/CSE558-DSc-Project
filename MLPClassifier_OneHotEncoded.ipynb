{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cap-diameter</th>\n",
       "      <th>stem-height</th>\n",
       "      <th>stem-width</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.26</td>\n",
       "      <td>16.95</td>\n",
       "      <td>17.09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.60</td>\n",
       "      <td>17.99</td>\n",
       "      <td>18.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.07</td>\n",
       "      <td>17.80</td>\n",
       "      <td>17.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.17</td>\n",
       "      <td>15.77</td>\n",
       "      <td>15.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.64</td>\n",
       "      <td>16.53</td>\n",
       "      <td>17.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cap-diameter  stem-height  stem-width    0    1    2    3    4    5    6  \\\n",
       "0         15.26        16.95       17.09  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "1         16.60        17.99       18.19  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "2         14.07        17.80       17.74  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "3         14.17        15.77       15.98  0.0  0.0  1.0  0.0  0.0  0.0  0.0   \n",
       "4         14.64        16.53       17.20  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "\n",
       "   ...   79   80   81   82   83   84   85   86   87   88  \n",
       "0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
       "1  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "2  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
       "3  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
       "4  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
       "\n",
       "[5 rows x 92 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open the CSV file\n",
    "df = pd.read_csv('Data_Preproc_OneHotEncoding.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Shape of One-Hot Encoded Data is:  (61069, 92)\n"
     ]
    }
   ],
   "source": [
    "# Read the labels\n",
    "print(\"The Shape of One-Hot Encoded Data is: \", df.shape)\n",
    "labels = pd.read_csv('Labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract values from the DataFrame\n",
    "X = df.values\n",
    "y = labels.values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1102: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.62321974\n",
      "Validation score: 0.750709\n",
      "Iteration 2, loss = 0.45175187\n",
      "Validation score: 0.841738\n",
      "Iteration 3, loss = 0.32745739\n",
      "Validation score: 0.893691\n",
      "Iteration 4, loss = 0.24925821\n",
      "Validation score: 0.917485\n",
      "Iteration 5, loss = 0.19609047\n",
      "Validation score: 0.939315\n",
      "Iteration 6, loss = 0.16085304\n",
      "Validation score: 0.951321\n",
      "Iteration 7, loss = 0.13616556\n",
      "Validation score: 0.953285\n",
      "Iteration 8, loss = 0.11823820\n",
      "Validation score: 0.960926\n",
      "Iteration 9, loss = 0.10396530\n",
      "Validation score: 0.965073\n",
      "Iteration 10, loss = 0.09118083\n",
      "Validation score: 0.963545\n",
      "Iteration 11, loss = 0.07955139\n",
      "Validation score: 0.975551\n",
      "Iteration 12, loss = 0.06817555\n",
      "Validation score: 0.981227\n",
      "Iteration 13, loss = 0.05836032\n",
      "Validation score: 0.984065\n",
      "Iteration 14, loss = 0.04983447\n",
      "Validation score: 0.985156\n",
      "Iteration 15, loss = 0.04331576\n",
      "Validation score: 0.987776\n",
      "Iteration 16, loss = 0.03869693\n",
      "Validation score: 0.989522\n",
      "Iteration 17, loss = 0.03370960\n",
      "Validation score: 0.990613\n",
      "Iteration 18, loss = 0.03060081\n",
      "Validation score: 0.991923\n",
      "Iteration 19, loss = 0.02748804\n",
      "Validation score: 0.992141\n",
      "Iteration 20, loss = 0.02502851\n",
      "Validation score: 0.993888\n",
      "Iteration 21, loss = 0.02262489\n",
      "Validation score: 0.994543\n",
      "Iteration 22, loss = 0.02209903\n",
      "Validation score: 0.994979\n",
      "Iteration 23, loss = 0.01924805\n",
      "Validation score: 0.994761\n",
      "Iteration 24, loss = 0.01813200\n",
      "Validation score: 0.994979\n",
      "Iteration 25, loss = 0.01693098\n",
      "Validation score: 0.995634\n",
      "Iteration 26, loss = 0.01580846\n",
      "Validation score: 0.995198\n",
      "Iteration 27, loss = 0.01482714\n",
      "Validation score: 0.996071\n",
      "Iteration 28, loss = 0.01444986\n",
      "Validation score: 0.996071\n",
      "Iteration 29, loss = 0.01353946\n",
      "Validation score: 0.995198\n",
      "Iteration 30, loss = 0.01276257\n",
      "Validation score: 0.994106\n",
      "Iteration 31, loss = 0.01213161\n",
      "Validation score: 0.995634\n",
      "Iteration 32, loss = 0.01140072\n",
      "Validation score: 0.996507\n",
      "Iteration 33, loss = 0.01078388\n",
      "Validation score: 0.996289\n",
      "Iteration 34, loss = 0.01016614\n",
      "Validation score: 0.996071\n",
      "Iteration 35, loss = 0.00998145\n",
      "Validation score: 0.996507\n",
      "Iteration 36, loss = 0.00910668\n",
      "Validation score: 0.996507\n",
      "Iteration 37, loss = 0.00902959\n",
      "Validation score: 0.996507\n",
      "Iteration 38, loss = 0.00875029\n",
      "Validation score: 0.995852\n",
      "Iteration 39, loss = 0.00852126\n",
      "Validation score: 0.996944\n",
      "Iteration 40, loss = 0.00787956\n",
      "Validation score: 0.996944\n",
      "Iteration 41, loss = 0.00747333\n",
      "Validation score: 0.995198\n",
      "Iteration 42, loss = 0.00735830\n",
      "Validation score: 0.997162\n",
      "Iteration 43, loss = 0.00696688\n",
      "Validation score: 0.996944\n",
      "Iteration 44, loss = 0.00659652\n",
      "Validation score: 0.996726\n",
      "Iteration 45, loss = 0.00613323\n",
      "Validation score: 0.996071\n",
      "Iteration 46, loss = 0.00663427\n",
      "Validation score: 0.997380\n",
      "Iteration 47, loss = 0.00592465\n",
      "Validation score: 0.996071\n",
      "Iteration 48, loss = 0.00640375\n",
      "Validation score: 0.997162\n",
      "Iteration 49, loss = 0.00535457\n",
      "Validation score: 0.997162\n",
      "Iteration 50, loss = 0.00518051\n",
      "Validation score: 0.996726\n",
      "Iteration 51, loss = 0.00472305\n",
      "Validation score: 0.996944\n",
      "Iteration 52, loss = 0.00478025\n",
      "Validation score: 0.996726\n",
      "Iteration 53, loss = 0.00556936\n",
      "Validation score: 0.997599\n",
      "Iteration 54, loss = 0.00584041\n",
      "Validation score: 0.997599\n",
      "Iteration 55, loss = 0.00441108\n",
      "Validation score: 0.996726\n",
      "Iteration 56, loss = 0.00416749\n",
      "Validation score: 0.997817\n",
      "Iteration 57, loss = 0.00387960\n",
      "Validation score: 0.997380\n",
      "Iteration 58, loss = 0.00424913\n",
      "Validation score: 0.997162\n",
      "Iteration 59, loss = 0.00350878\n",
      "Validation score: 0.996071\n",
      "Iteration 60, loss = 0.00373267\n",
      "Validation score: 0.996944\n",
      "Iteration 61, loss = 0.00396132\n",
      "Validation score: 0.995634\n",
      "Iteration 62, loss = 0.00398279\n",
      "Validation score: 0.997817\n",
      "Iteration 63, loss = 0.00372766\n",
      "Validation score: 0.997817\n",
      "Iteration 64, loss = 0.00346720\n",
      "Validation score: 0.997817\n",
      "Iteration 65, loss = 0.00382100\n",
      "Validation score: 0.996944\n",
      "Iteration 66, loss = 0.00310497\n",
      "Validation score: 0.997380\n",
      "Iteration 67, loss = 0.00343331\n",
      "Validation score: 0.997817\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(batch_size=128, early_stopping=True, hidden_layer_sizes=(10, 5),\n",
       "              max_iter=100, random_state=42, verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(batch_size=128, early_stopping=True, hidden_layer_sizes=(10, 5),\n",
       "              max_iter=100, random_state=42, verbose=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(batch_size=128, early_stopping=True, hidden_layer_sizes=(10, 5),\n",
       "              max_iter=100, random_state=42, verbose=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(10, 5), \n",
    "                    activation='relu', \n",
    "                    random_state=42, \n",
    "                    early_stopping=True, \n",
    "                    max_iter=100,\n",
    "                    batch_size=128,\n",
    "                    verbose=True)\n",
    "\n",
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9979696096410794\n",
      "[[6764   17]\n",
      " [  14 8473]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           e       1.00      1.00      1.00      6781\n",
      "           p       1.00      1.00      1.00      8487\n",
      "\n",
      "    accuracy                           1.00     15268\n",
      "   macro avg       1.00      1.00      1.00     15268\n",
      "weighted avg       1.00      1.00      1.00     15268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict the labels of the test set: y_pred\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "# Compute and print the confusion matrix and classification report\n",
    "print(\"Accuracy: {}\".format(mlp.score(X_test, y_test)))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1102: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.59851891\n",
      "Validation score: 0.796333\n",
      "Iteration 2, loss = 0.41215731\n",
      "Validation score: 0.878629\n",
      "Iteration 3, loss = 0.30617104\n",
      "Validation score: 0.907662\n",
      "Iteration 4, loss = 0.23559579\n",
      "Validation score: 0.928618\n",
      "Iteration 5, loss = 0.18304190\n",
      "Validation score: 0.943462\n",
      "Iteration 6, loss = 0.14530654\n",
      "Validation score: 0.954813\n",
      "Iteration 7, loss = 0.11864977\n",
      "Validation score: 0.964418\n",
      "Iteration 8, loss = 0.09980906\n",
      "Validation score: 0.970312\n",
      "Iteration 9, loss = 0.08463902\n",
      "Validation score: 0.975551\n",
      "Iteration 10, loss = 0.07401303\n",
      "Validation score: 0.979480\n",
      "Iteration 11, loss = 0.06440196\n",
      "Validation score: 0.981227\n",
      "Iteration 12, loss = 0.05678358\n",
      "Validation score: 0.982973\n",
      "Iteration 13, loss = 0.05089071\n",
      "Validation score: 0.982537\n",
      "Iteration 14, loss = 0.04617216\n",
      "Validation score: 0.984283\n",
      "Iteration 15, loss = 0.04244176\n",
      "Validation score: 0.986248\n",
      "Iteration 16, loss = 0.03844934\n",
      "Validation score: 0.986684\n",
      "Iteration 17, loss = 0.03540565\n",
      "Validation score: 0.987557\n",
      "Iteration 18, loss = 0.03323693\n",
      "Validation score: 0.988649\n",
      "Iteration 19, loss = 0.03119880\n",
      "Validation score: 0.988867\n",
      "Iteration 20, loss = 0.02912618\n",
      "Validation score: 0.989304\n",
      "Iteration 21, loss = 0.02755443\n",
      "Validation score: 0.989740\n",
      "Iteration 22, loss = 0.02570456\n",
      "Validation score: 0.989522\n",
      "Iteration 23, loss = 0.02430023\n",
      "Validation score: 0.990613\n",
      "Iteration 24, loss = 0.02272683\n",
      "Validation score: 0.991705\n",
      "Iteration 25, loss = 0.02189514\n",
      "Validation score: 0.991923\n",
      "Iteration 26, loss = 0.02080942\n",
      "Validation score: 0.992141\n",
      "Iteration 27, loss = 0.01961795\n",
      "Validation score: 0.992360\n",
      "Iteration 28, loss = 0.01908155\n",
      "Validation score: 0.993233\n",
      "Iteration 29, loss = 0.01778078\n",
      "Validation score: 0.992360\n",
      "Iteration 30, loss = 0.01724834\n",
      "Validation score: 0.994106\n",
      "Iteration 31, loss = 0.01631483\n",
      "Validation score: 0.992796\n",
      "Iteration 32, loss = 0.01582274\n",
      "Validation score: 0.993888\n",
      "Iteration 33, loss = 0.01462693\n",
      "Validation score: 0.993888\n",
      "Iteration 34, loss = 0.01422047\n",
      "Validation score: 0.993015\n",
      "Iteration 35, loss = 0.01382228\n",
      "Validation score: 0.994324\n",
      "Iteration 36, loss = 0.01278389\n",
      "Validation score: 0.994979\n",
      "Iteration 37, loss = 0.01299909\n",
      "Validation score: 0.994979\n",
      "Iteration 38, loss = 0.01230934\n",
      "Validation score: 0.993888\n",
      "Iteration 39, loss = 0.01160132\n",
      "Validation score: 0.994324\n",
      "Iteration 40, loss = 0.01120689\n",
      "Validation score: 0.994979\n",
      "Iteration 41, loss = 0.01069401\n",
      "Validation score: 0.994979\n",
      "Iteration 42, loss = 0.01028602\n",
      "Validation score: 0.994324\n",
      "Iteration 43, loss = 0.01009055\n",
      "Validation score: 0.994543\n",
      "Iteration 44, loss = 0.00946903\n",
      "Validation score: 0.995634\n",
      "Iteration 45, loss = 0.00930545\n",
      "Validation score: 0.994979\n",
      "Iteration 46, loss = 0.00901589\n",
      "Validation score: 0.995416\n",
      "Iteration 47, loss = 0.00882421\n",
      "Validation score: 0.995852\n",
      "Iteration 48, loss = 0.00841888\n",
      "Validation score: 0.996071\n",
      "Iteration 49, loss = 0.00824162\n",
      "Validation score: 0.996071\n",
      "Iteration 50, loss = 0.00784246\n",
      "Validation score: 0.996071\n",
      "Iteration 51, loss = 0.00735762\n",
      "Validation score: 0.996071\n",
      "Iteration 52, loss = 0.00728536\n",
      "Validation score: 0.996289\n",
      "Iteration 53, loss = 0.00718096\n",
      "Validation score: 0.995852\n",
      "Iteration 54, loss = 0.00709646\n",
      "Validation score: 0.995634\n",
      "Iteration 55, loss = 0.00693342\n",
      "Validation score: 0.996289\n",
      "Iteration 56, loss = 0.00672742\n",
      "Validation score: 0.996507\n",
      "Iteration 57, loss = 0.00702997\n",
      "Validation score: 0.996944\n",
      "Iteration 58, loss = 0.00632357\n",
      "Validation score: 0.996289\n",
      "Iteration 59, loss = 0.00560202\n",
      "Validation score: 0.995852\n",
      "Iteration 60, loss = 0.00593899\n",
      "Validation score: 0.996071\n",
      "Iteration 61, loss = 0.00599109\n",
      "Validation score: 0.996726\n",
      "Iteration 62, loss = 0.00653355\n",
      "Validation score: 0.996507\n",
      "Iteration 63, loss = 0.00543161\n",
      "Validation score: 0.996944\n",
      "Iteration 64, loss = 0.00539689\n",
      "Validation score: 0.996507\n",
      "Iteration 65, loss = 0.00522621\n",
      "Validation score: 0.996726\n",
      "Iteration 66, loss = 0.00501299\n",
      "Validation score: 0.996289\n",
      "Iteration 67, loss = 0.00475561\n",
      "Validation score: 0.997817\n",
      "Iteration 68, loss = 0.00476992\n",
      "Validation score: 0.997380\n",
      "Iteration 69, loss = 0.00475787\n",
      "Validation score: 0.996507\n",
      "Iteration 70, loss = 0.00455580\n",
      "Validation score: 0.996507\n",
      "Iteration 71, loss = 0.00494849\n",
      "Validation score: 0.996289\n",
      "Iteration 72, loss = 0.00446672\n",
      "Validation score: 0.997599\n",
      "Iteration 73, loss = 0.00453796\n",
      "Validation score: 0.997162\n",
      "Iteration 74, loss = 0.00515898\n",
      "Validation score: 0.996726\n",
      "Iteration 75, loss = 0.00417337\n",
      "Validation score: 0.997162\n",
      "Iteration 76, loss = 0.00436090\n",
      "Validation score: 0.997162\n",
      "Iteration 77, loss = 0.00445983\n",
      "Validation score: 0.998035\n",
      "Iteration 78, loss = 0.00394832\n",
      "Validation score: 0.996507\n",
      "Iteration 79, loss = 0.00397361\n",
      "Validation score: 0.998035\n",
      "Iteration 80, loss = 0.00375366\n",
      "Validation score: 0.996726\n",
      "Iteration 81, loss = 0.00372655\n",
      "Validation score: 0.997599\n",
      "Iteration 82, loss = 0.00395404\n",
      "Validation score: 0.998035\n",
      "Iteration 83, loss = 0.00370804\n",
      "Validation score: 0.997162\n",
      "Iteration 84, loss = 0.00367685\n",
      "Validation score: 0.997380\n",
      "Iteration 85, loss = 0.00350070\n",
      "Validation score: 0.997162\n",
      "Iteration 86, loss = 0.00376356\n",
      "Validation score: 0.998472\n",
      "Iteration 87, loss = 0.00325533\n",
      "Validation score: 0.998254\n",
      "Iteration 88, loss = 0.00300537\n",
      "Validation score: 0.997380\n",
      "Iteration 89, loss = 0.00358563\n",
      "Validation score: 0.998035\n",
      "Iteration 90, loss = 0.00365682\n",
      "Validation score: 0.997599\n",
      "Iteration 91, loss = 0.00304330\n",
      "Validation score: 0.997817\n",
      "Iteration 92, loss = 0.00351696\n",
      "Validation score: 0.996726\n",
      "Iteration 93, loss = 0.00284803\n",
      "Validation score: 0.997380\n",
      "Iteration 94, loss = 0.00301836\n",
      "Validation score: 0.997599\n",
      "Iteration 95, loss = 0.00304041\n",
      "Validation score: 0.998254\n",
      "Iteration 96, loss = 0.00340761\n",
      "Validation score: 0.997599\n",
      "Iteration 97, loss = 0.00262526\n",
      "Validation score: 0.996944\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(batch_size=128, early_stopping=True, hidden_layer_sizes=(10, 5),\n",
       "              max_iter=100, random_state=42, verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(batch_size=128, early_stopping=True, hidden_layer_sizes=(10, 5),\n",
       "              max_iter=100, random_state=42, verbose=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(batch_size=128, early_stopping=True, hidden_layer_sizes=(10, 5),\n",
       "              max_iter=100, random_state=42, verbose=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PCA with 51 components\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=51)\n",
    "pca.fit(X)\n",
    "X_pca = pca.transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(X_pca, y, test_size=0.25, random_state=42)\n",
    "\n",
    "mlp_pca = MLPClassifier(hidden_layer_sizes=(10, 5),\n",
    "                        activation='relu',\n",
    "                        random_state=42,\n",
    "                        early_stopping=True,\n",
    "                        max_iter=100,\n",
    "                        batch_size=128,\n",
    "                        verbose=True)\n",
    "\n",
    "mlp_pca.fit(X_train_pca, y_train_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9984935813466073\n",
      "[[6772    9]\n",
      " [  14 8473]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           e       1.00      1.00      1.00      6781\n",
      "           p       1.00      1.00      1.00      8487\n",
      "\n",
      "    accuracy                           1.00     15268\n",
      "   macro avg       1.00      1.00      1.00     15268\n",
      "weighted avg       1.00      1.00      1.00     15268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict the labels of the test set: y_pred\n",
    "y_pred_pca = mlp_pca.predict(X_test_pca)\n",
    "\n",
    "# Compute and print the confusion matrix and classification report\n",
    "print(\"Accuracy: {}\".format(mlp_pca.score(X_test_pca, y_test_pca)))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(confusion_matrix(y_test_pca, y_pred_pca))\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test_pca, y_pred_pca))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
